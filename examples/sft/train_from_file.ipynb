{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this model, click **Runtime** > **Run all**.\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-ART-blue?logo=github)](https://github.com/OpenPipe/ART)\n",
    "[![Discord](https://img.shields.io/badge/Discord-Join-7289da?logo=discord&logoColor=white)](https://discord.gg/zbBHRUpwf4)\n",
    "[![Docs](https://img.shields.io/badge/Docs-ART-green)](https://docs.art-e.dev/fundamentals/sft-training)\n",
    "\n",
    "This notebook demonstrates how to fine-tune a model using **supervised fine-tuning (SFT)** with ART. We'll download a real dataset and train from a JSONL file using `train_sft_from_file`.\n",
    "\n",
    "For distillation (training from a teacher model's outputs), see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb).\n",
    "\n",
    "Completions and metrics will be logged to [Weights & Biases](https://wandb.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!uv pip install openpipe-art==0.5.10 datasets --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "Set your `WANDB_API_KEY` to use the serverless backend. Get one at [wandb.ai](https://wandb.ai/home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "WANDB_API_KEY = \"\"  # required\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "SFT training expects a JSONL file where each line has a `messages` array in the [OpenAI chat format](https://platform.openai.com/docs/api-reference/chat). The last message must be from the `assistant` role.\n",
    "\n",
    "We'll use [HuggingFaceH4/no_robots](https://huggingface.co/datasets/HuggingFaceH4/no_robots), a high-quality dataset of 10k human-written instruction-following examples that already has a `messages` column in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "with open(\"train.jsonl\", \"w\") as f:\n",
    "    for row in load_dataset(\"HuggingFaceH4/no_robots\", split=\"train\"):\n",
    "        f.write(json.dumps({\"messages\": row[\"messages\"]}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Use `train_sft_from_file` to train directly from the JSONL file. It handles batching, learning rate scheduling, and logging automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "from art.utils.sft import train_sft_from_file\n",
    "\n",
    "backend = ServerlessBackend()\n",
    "model = art.TrainableModel(\n",
    "    name=\"sft-no-robots\",\n",
    "    project=\"sft-example\",\n",
    "    base_model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    ")\n",
    "await model.register(backend)\n",
    "\n",
    "await train_sft_from_file(\n",
    "    model=model,\n",
    "    file_path=\"train.jsonl\",\n",
    "    epochs=3,\n",
    "    batch_size=2,\n",
    "    peak_lr=2e-4,\n",
    "    schedule_type=\"cosine\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "Try the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = model.openai_client()\n",
    "completion = await client.chat.completions.create(\n",
    "    model=model.get_inference_name(),\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Write a haiku about programming.\"}],\n",
    ")\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For more details, see the [SFT Training docs](https://docs.art-e.dev/fundamentals/sft-training). For distillation, see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb). Questions? Join the [Discord](https://discord.gg/zbBHRUpwf4)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
