{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train this model, click **Runtime** > **Run all**.\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-ART-blue?logo=github)](https://github.com/OpenPipe/ART)\n",
    "[![Discord](https://img.shields.io/badge/Discord-Join-7289da?logo=discord&logoColor=white)](https://discord.gg/zbBHRUpwf4)\n",
    "[![Docs](https://img.shields.io/badge/Docs-ART-green)](https://docs.art-e.dev/fundamentals/sft-training)\n",
    "\n",
    "This notebook demonstrates how to fine-tune a model using **supervised fine-tuning (SFT)** with ART. We'll download a text-to-SQL dataset and train from a JSONL file using `train_sft_from_file`.\n",
    "\n",
    "For distillation (training from a teacher model's outputs), see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb).\n",
    "\n",
    "Completions and metrics will be logged to [Weights & Biases](https://wandb.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.9' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.13 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!uv pip install \"openpipe-art @ git+https://github.com/openpipe/art.git@main\" datasets --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "Set your `WANDB_API_KEY` to use the serverless backend. Get one at [wandb.ai](https://wandb.ai/home)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "WANDB_API_KEY = \"\"  # required\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "SFT training expects a JSONL file where each line has a `messages` array in the [OpenAI chat format](https://platform.openai.com/docs/api-reference/chat). The last message must be from the `assistant` role.\n",
    "\n",
    "We'll use [gretelai/synthetic_text_to_sql](https://huggingface.co/datasets/gretelai/synthetic_text_to_sql), a large synthetic text-to-SQL dataset covering 100 domains and multiple SQL complexity levels. Each example has a schema context, a natural language question, and the corresponding SQL query. We convert the first 2,000 examples into chat format with the schema as the system message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"gretelai/synthetic_text_to_sql\", split=\"train\")\n",
    "\n",
    "with open(\"train.jsonl\", \"w\") as f:\n",
    "    for row in ds.select(range(20)):\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": row[\"sql_context\"]},\n",
    "            {\"role\": \"user\", \"content\": row[\"sql_prompt\"]},\n",
    "            {\"role\": \"assistant\", \"content\": row[\"sql\"]},\n",
    "        ]\n",
    "        f.write(json.dumps({\"messages\": messages}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Use `train_sft_from_file` to train directly from the JSONL file. It handles batching, learning rate scheduling, and logging automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import art\n",
    "from art.serverless.backend import ServerlessBackend\n",
    "from art.utils.sft import train_sft_from_file\n",
    "\n",
    "backend = ServerlessBackend()\n",
    "model = art.TrainableModel(\n",
    "    name=\"sft-text-to-sql\",\n",
    "    project=\"sft-example\",\n",
    "    base_model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
    ")\n",
    "await model.register(backend)\n",
    "\n",
    "await train_sft_from_file(\n",
    "    model=model,\n",
    "    file_path=\"train.jsonl\",\n",
    "    epochs=3,\n",
    "    batch_size=2,\n",
    "    peak_lr=2e-4,\n",
    "    schedule_type=\"cosine\",\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Using the Model\n\nTry the trained model with a new text-to-SQL question."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "client = model.openai_client()\ncompletion = await client.chat.completions.create(\n    model=model.get_inference_name(),\n    messages=[\n        {\"role\": \"system\", \"content\": \"CREATE TABLE equipment_maintenance (equipment_type VARCHAR(255), maintenance_frequency INT);\"},\n        {\"role\": \"user\", \"content\": \"List all the unique equipment types and their corresponding total maintenance frequency from the equipment_maintenance table.\"},\n    ],\n)\nprint(completion.choices[0].message.content)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "For more details, see the [SFT Training docs](https://docs.art-e.dev/fundamentals/sft-training). For distillation, see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb). Questions? Join the [Discord](https://discord.gg/zbBHRUpwf4)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}