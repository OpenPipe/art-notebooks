{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "To train this model, click **Runtime** > **Run all**.\n\n[![GitHub](https://img.shields.io/badge/GitHub-ART-blue?logo=github)](https://github.com/OpenPipe/ART)\n[![Discord](https://img.shields.io/badge/Discord-Join-7289da?logo=discord&logoColor=white)](https://discord.gg/zbBHRUpwf4)\n[![Docs](https://img.shields.io/badge/Docs-ART-green)](https://docs.art-e.dev/fundamentals/sft-training)\n\nThis notebook demonstrates how to fine-tune a model using **supervised fine-tuning (SFT)** with ART. We'll download a real dataset and train from a JSONL file using `train_sft_from_file`.\n\nFor distillation (training from a teacher model's outputs), see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb).\n\nCompletions and metrics will be logged to [Weights & Biases](https://wandb.ai)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%capture\n!uv pip install openpipe-art==0.5.9 datasets --prerelease allow --no-cache-dir"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Environment Variables\n\nSet your `WANDB_API_KEY` to use the serverless backend. Get one at [wandb.ai](https://wandb.ai/home)."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\n\nWANDB_API_KEY = \"\"  # required\nif WANDB_API_KEY:\n    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Dataset\n",
    "\n",
    "SFT training expects a JSONL file where each line has a `messages` array in the [OpenAI chat format](https://platform.openai.com/docs/api-reference/chat). The last message must be from the `assistant` role.\n",
    "\n",
    "We'll use [HuggingFaceH4/no_robots](https://huggingface.co/datasets/HuggingFaceH4/no_robots), a high-quality dataset of 10k human-written instruction-following examples that already has a `messages` column in the right format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "with open(\"train.jsonl\", \"w\") as f:\n",
    "    for row in load_dataset(\"HuggingFaceH4/no_robots\", split=\"train\"):\n",
    "        f.write(json.dumps({\"messages\": row[\"messages\"]}) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### Training\n\nUse `train_sft_from_file` to train directly from the JSONL file. It handles batching, learning rate scheduling, and logging automatically."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import art\nfrom art.serverless.backend import ServerlessBackend\nfrom art.utils.sft import train_sft_from_file\n\nbackend = ServerlessBackend()\nmodel = art.TrainableModel(\n    name=\"sft-no-robots\",\n    project=\"sft-example\",\n    base_model=\"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n)\nawait model.register(backend)\n\nawait train_sft_from_file(\n    model=model,\n    file_path=\"train.jsonl\",\n    epochs=3,\n    batch_size=2,\n    peak_lr=2e-4,\n    schedule_type=\"cosine\",\n    verbose=True,\n)\n\nprint(\"Training complete!\")"
  },
  {
   "cell_type": "markdown",
   "source": "### Inference\n\nTry the trained model.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "client = model.openai_client()\ncompletion = await client.chat.completions.create(\n    model=model.get_inference_name(),\n    messages=[{\"role\": \"user\", \"content\": \"Write a haiku about programming.\"}],\n)\nprint(completion.choices[0].message.content)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\nFor more details, see the [SFT Training docs](https://docs.art-e.dev/fundamentals/sft-training). For distillation, see the [distillation notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/distillation.ipynb). Questions? Join the [Discord](https://discord.gg/zbBHRUpwf4)!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}