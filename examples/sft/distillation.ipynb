{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run this notebook, click **Runtime** > **Run all**.\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-ART-blue?logo=github)](https://github.com/OpenPipe/ART)\n",
    "[![Discord](https://img.shields.io/badge/Discord-Join-7289da?logo=discord&logoColor=white)](https://discord.gg/zbBHRUpwf4)\n",
    "[![Docs](https://img.shields.io/badge/Docs-ART-green)](https://docs.art-e.dev/fundamentals/sft-training)\n",
    "\n",
    "This notebook demonstrates **distillation** with ART — training a small model on completions generated by a larger teacher model.\n",
    "\n",
    "We'll distill a text-to-SQL capability: a large teacher model generates SQL queries from natural language questions over an e-commerce schema, and a smaller student model learns to produce the same quality output. This is a common production pattern — large models handle complex joins, subqueries, and aggregations well, but are too slow or expensive for real-time use.\n",
    "\n",
    "For training from a static JSONL dataset, see the [SFT notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/sft.ipynb).\n",
    "\n",
    "Completions and metrics will be logged to [Weights & Biases](https://wandb.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "!uv pip install openpipe-art==0.5.9 openai --prerelease allow --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Variables\n",
    "\n",
    "Set your `WANDB_API_KEY` to call the teacher model via [W&B Inference](https://wandb.ai/site/inference) and to use the serverless backend — get one at [wandb.ai](https://wandb.ai/settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "WANDB_API_KEY = \"\"  # required\n",
    "\n",
    "if WANDB_API_KEY:\n",
    "    os.environ[\"WANDB_API_KEY\"] = WANDB_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Teacher Completions\n",
    "\n",
    "We define an e-commerce database schema and a set of natural language questions ranging from simple lookups to complex aggregations with subqueries. The teacher model generates SQL for each question via [W&B Inference](https://wandb.ai/site/inference), and we collect these as training trajectories for the student."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "\n",
    "from openai import AsyncOpenAI\n",
    "\n",
    "import art\n",
    "\n",
    "TEACHER_MODEL = \"zai-org/GLM-5-FP8\"\n",
    "\n",
    "teacher_client = AsyncOpenAI(\n",
    "    api_key=os.environ[\"WANDB_API_KEY\"],\n",
    "    base_url=\"https://api.inference.wandb.ai/v1\",\n",
    ")\n",
    "\n",
    "system_prompt = \"\"\"You are a SQL expert. Given a database schema and a natural language question, write a single SQL query that answers the question. Return only the SQL query, no explanation.\n",
    "\n",
    "Schema:\n",
    "  customers (id INT, name TEXT, email TEXT, signup_date DATE, plan TEXT)\n",
    "  orders (id INT, customer_id INT, total DECIMAL, status TEXT, created_at TIMESTAMP)\n",
    "  order_items (id INT, order_id INT, product_id INT, quantity INT, unit_price DECIMAL)\n",
    "  products (id INT, name TEXT, category TEXT, price DECIMAL, stock INT)\n",
    "\n",
    "Notes:\n",
    "  - orders.status is one of: 'pending', 'shipped', 'delivered', 'cancelled'\n",
    "  - customers.plan is one of: 'free', 'pro', 'enterprise'\n",
    "  - order_items.unit_price is the price at time of purchase (may differ from products.price)\"\"\"\n",
    "\n",
    "questions = [\n",
    "    \"Which customers signed up in the last 30 days?\",\n",
    "    \"What's the total revenue by product category for Q4 2024?\",\n",
    "    \"Find customers who placed more than 5 orders but never bought anything in the 'Electronics' category.\",\n",
    "    \"What's the average order value for each customer plan tier, excluding cancelled orders?\",\n",
    "    \"List the top 10 products by revenue that have less than 50 units in stock.\",\n",
    "    \"Find customers whose total spending exceeds the average customer spending by more than 2x.\",\n",
    "    \"What percentage of orders from the last month are still in 'pending' status, broken down by customer plan?\",\n",
    "    \"Show the month-over-month growth rate of new customer signups for the past 12 months.\",\n",
    "    \"Which products have been ordered together in the same order more than 10 times?\",\n",
    "    \"Find customers who haven't placed an order in the last 90 days but previously ordered at least once a month for 3 consecutive months.\",\n",
    "    \"What is the customer lifetime value (total spending) for each signup cohort month?\",\n",
    "    \"Rank product categories by their return customer rate (customers who bought from the same category more than once).\",\n",
    "]\n",
    "\n",
    "\n",
    "async def get_teacher_completion(question):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "    ]\n",
    "    completion = await teacher_client.chat.completions.create(\n",
    "        model=TEACHER_MODEL,\n",
    "        messages=messages,\n",
    "    )\n",
    "    response = completion.choices[0].message.content\n",
    "    print(f\"Q: {question}\\n{response}\\n\")\n",
    "    return art.Trajectory(\n",
    "        messages_and_choices=[\n",
    "            *messages,\n",
    "            {\"role\": \"assistant\", \"content\": response},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "trajectories = await asyncio.gather(*[get_teacher_completion(q) for q in questions])\n",
    "trajectories = list(trajectories)\n",
    "\n",
    "print(f\"Generated {len(trajectories)} trajectories from teacher model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Use `create_sft_dataset_iterator` to train the student model on teacher outputs. It computes the learning rate schedule over the full dataset and yields chunks, so each `train_sft` call logs its own metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from art.serverless.backend import ServerlessBackend\nfrom art.utils.sft import create_sft_dataset_iterator\n\nbackend = ServerlessBackend()\nstudent = art.TrainableModel(\n    name=\"distillation-text-to-sql\",\n    project=\"sft-distillation\",\n    base_model=\"OpenPipe/Qwen3-14B-Instruct\",\n)\nawait student.register(backend)\n\nfor chunk in create_sft_dataset_iterator(trajectories, epochs=3, peak_lr=2e-4):\n    await student.train_sft(chunk.trajectories, chunk.config)\n\nprint(\"Training complete!\")"
  },
  {
   "cell_type": "markdown",
   "source": "### RL Training with RULER\n\nNow we'll improve the SFT-trained student using **reinforcement learning**. Instead of imitating the teacher's outputs, the model learns to maximize a reward signal from an LLM judge.\n\n[RULER](https://docs.art-e.dev/fundamentals/ruler) scores multiple completions per question *relative to each other* — no hand-crafted reward function needed. We use GLM-5 via W&B Inference as the judge.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from art.rewards import ruler_score_group\n\nJUDGE_MODEL = \"openai/zai-org/GLM-5-FP8\"\njudge_litellm_params = {\n    \"api_base\": \"https://api.inference.wandb.ai/v1\",\n    \"api_key\": os.environ[\"WANDB_API_KEY\"],\n}\n\nclient = student.openai_client()\n\n\nasync def rollout(question: str) -> art.Trajectory:\n    messages = [\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": question},\n    ]\n    completion = await client.chat.completions.create(\n        model=student.get_inference_name(),\n        messages=messages,\n    )\n    return art.Trajectory(\n        messages_and_choices=[*messages, completion.choices[0]],\n    )",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "NUM_GENERATIONS = 4  # trajectories per question (RULER compares these)\nRL_STEPS = 3\n\nfor step in range(RL_STEPS):\n    groups = await art.gather_trajectory_groups(\n        (\n            art.TrajectoryGroup(\n                rollout(question) for _ in range(NUM_GENERATIONS)\n            )\n            for question in questions\n        ),\n        after_each=lambda group: ruler_score_group(\n            group,\n            judge_model=JUDGE_MODEL,\n            extra_litellm_params=judge_litellm_params,\n            swallow_exceptions=True,\n        ),\n        pbar_desc=f\"rl step {step}\",\n    )\n\n    result = await backend.train(student, groups, learning_rate=5e-6)\n    await student.log(groups, metrics=result.metrics, step=result.step, split=\"train\")\n    print(f\"Step {step}: {result.metrics}\")\n\nprint(\"RL training complete!\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Inference\n\nTry the trained model with a new question.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "completion = await client.chat.completions.create(\n    model=student.get_inference_name(),\n    messages=[\n        {\"role\": \"system\", \"content\": system_prompt},\n        {\"role\": \"user\", \"content\": \"Which product category has the highest average order value?\"},\n    ],\n)\nprint(completion.choices[0].message.content)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\nFor more details, see the [SFT Training docs](https://docs.art-e.dev/fundamentals/sft-training) and [RULER docs](https://docs.art-e.dev/fundamentals/ruler). For training from a static dataset, see the [SFT notebook](https://github.com/OpenPipe/ART/blob/main/examples/sft/sft.ipynb). Questions? Join the [Discord](https://discord.gg/zbBHRUpwf4)!"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}